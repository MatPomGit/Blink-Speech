# Blink Speech: Kompletna Dokumentacja Techniczna

> **Zamieniamy mrugniÄ™cia i spojrzenia w gÅ‚os â€“ komunikacja bez granic.**

**Blink Speech** to dziaÅ‚ajÄ…ca w przeglÄ…darce aplikacja wspomagajÄ…ca komunikacjÄ™, ktÃ³ra przeksztaÅ‚ca intencjonalne wzorce mrugniÄ™Ä‡ i gesty wzrokowe w wypowiadane frazy. Zbudowana przy uÅ¼yciu nowoczesnych technologii webowych, dziaÅ‚a caÅ‚kowicie po stronie klienta, zapewniajÄ…c prywatnoÅ›Ä‡ uÅ¼ytkownika dziÄ™ki podejÅ›ciu wymagajÄ…cemu zero instalacji i priorytetowi anonimowoÅ›ci. ğŸ‘ï¸â€ğŸ—¨ï¸ â†’ ğŸ—£ï¸

---

## ğŸ“š **Nawigacja po Dokumentacji**

### ğŸš€ **Pierwsze Kroki**
- [**ğŸ“– Kompletny Pakiet Dokumentacji**](./docs/README.md) - GÅ‚Ã³wny hub dokumentacji
- [**ğŸ› ï¸ Przewodnik Instalacji**](./docs/installation.md) - Konfiguracja dla Å›rodowiska deweloperskiego i produkcyjnego
- [**ğŸ‘¤ Przewodnik UÅ¼ytkownika**](./docs/user-guide.md) - Jak efektywnie korzystaÄ‡ z Blink Speech
- [**ğŸ”§ Konfiguracja**](./docs/configuration.md) - Zmienne Å›rodowiskowe i ustawienia

### ğŸ—ï¸ **Architektura i RozwÃ³j**
- [**ğŸ›ï¸ Architektura Systemu**](./docs/architecture.md) - Projekt techniczny i przepÅ‚yw danych
- [**ğŸ’» Przewodnik Deweloperski**](./docs/development-guide.md) - PrzepÅ‚ywy pracy i najlepsze praktyki dla programistÃ³w
- [**ğŸ§© Komponenty Frontend**](./docs/frontend-components.md) - Komponenty React i hooki
- [**ğŸ”— Dokumentacja API**](./docs/api-documentation.md) - Endpointy backendu i baza danych

### ğŸ”¬ **Kluczowe Technologie**
- [**ğŸ‘ï¸ Detekcja GestÃ³w**](./docs/gesture-detection.md) - Implementacja widzenia komputerowego
- [**ğŸµ Synteza Mowy**](./docs/speech-synthesis.md) - Integracja text-to-speech
- [**ğŸŒ Architektura Frontend**](./docs/frontend.md) - Implementacja React + Vite

### ğŸš€ **Operacje**
- [**ğŸš€ Przewodnik WdroÅ¼enia**](./docs/deployment.md) - Strategie wdraÅ¼ania produkcyjnego
- [**ğŸ” RozwiÄ…zywanie ProblemÃ³w**](./docs/troubleshooting.md) - Typowe problemy i rozwiÄ…zania

---

## ğŸ› ï¸ **Aktualny Stos Technologiczny**

![React](https://img.shields.io/badge/React_18-20232A?style=for-the-badge&logo=react&logoColor=61DAFB)
![Vite](https://img.shields.io/badge/Vite-646CFF?style=for-the-badge&logo=vite&logoColor=white)
![TypeScript](https://img.shields.io/badge/TypeScript-3178C6?style=for-the-badge&logo=typescript&logoColor=white)
![WebGazer.js](https://img.shields.io/badge/WebGazer.js-FF6F00?style=for-the-badge&logo=javascript&logoColor=white)
![MediaPipe](https://img.shields.io/badge/MediaPipe-4285F4?style=for-the-badge&logo=google&logoColor=white)
![TensorFlow.js](https://img.shields.io/badge/TensorFlow.js-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white)
![Supabase](https://img.shields.io/badge/Supabase-3ECF8E?style=for-the-badge&logo=supabase&logoColor=white)
![Tailwind CSS](https://img.shields.io/badge/Tailwind_CSS-38B2AC?style=for-the-badge&logo=tailwind-css&logoColor=white)
![Radix UI](https://img.shields.io/badge/Radix_UI-161618?style=for-the-badge&logo=radix-ui&logoColor=white)
![Next.js](https://img.shields.io/badge/Next.js_API-000000?style=for-the-badge&logo=nextdotjs&logoColor=white)
![Web Speech API](https://img.shields.io/badge/Web_Speech_API-FF4081?style=for-the-badge&logo=googlechrome&logoColor=white)

---

## ğŸ¯ **Szybki Start**

1. **ğŸ“¥ Klonowanie i Instalacja**
   ```bash
   git clone https://github.com/MatPomGit/Blink-Speech.git
   cd Blink-Speech
   cd frontend && npm install
   cd ../backend && npm install
   ```

2. **âš™ï¸ Konfiguracja Åšrodowiska**
   - Skonfiguruj projekt [Supabase](https://supabase.com)
   - Skonfiguruj zmienne Å›rodowiskowe (zobacz [Przewodnik Konfiguracji](./docs/configuration.md))

3. **ğŸš€ Uruchomienie w Trybie Deweloperskim**
   ```bash
   # Frontend (Terminal 1)
   cd frontend && npm run dev
   
   # Backend (Terminal 2)  
   cd backend && npm run dev
   ```

4. **ğŸ¯ RozpoczÄ™cie UÅ¼ytkowania**
   - OtwÃ³rz `https://localhost:5173`
   - PozwÃ³l na dostÄ™p do kamery
   - UkoÅ„cz kalibracjÄ™
   - Zacznij komunikowaÄ‡ siÄ™ przy uÅ¼yciu gestÃ³w!

---

## ğŸ§  **Podstawowe Koncepcje**

Blink Speech wykorzystuje zaawansowane widzenie komputerowe do tÅ‚umaczenia ruchÃ³w oczu na mowÄ™ poprzez wykrywanie dwÃ³ch podstawowych sygnaÅ‚Ã³w wejÅ›ciowych przez kamerÄ™ internetowÄ… uÅ¼ytkownika: **wzorcÃ³w mrugniÄ™Ä‡** i **kierunkÃ³w spojrzenia**. Te sygnaÅ‚y sÄ… Å‚Ä…czone w celu wywoÅ‚ania predefiniowanych lub w peÅ‚ni konfigurowalnych fraz.

**WyjaÅ›nienie:** System dziaÅ‚a w czasie rzeczywistym, analizujÄ…c obraz z kamery i wykrywajÄ…c charakterystyczne ruchy oczu. KaÅ¼de mrugniÄ™cie jest rejestrowane z dokÅ‚adnoÅ›ciÄ… co do milisekundy, a system rozpoznaje rÃ³Å¼ne typy mrugniÄ™Ä‡ na podstawie ich czasu trwania i czÄ™stotliwoÅ›ci wystÄ™powania.

### ğŸ¯ **ObsÅ‚ugiwane Gesty**

| Typ Gestu | Wzorzec | DomyÅ›lna Fraza | Przypadek UÅ¼ycia |
|-------------|---------|----------------|----------|
| **Pojedyncze MrugniÄ™cie** | Jedno szybkie mrugniÄ™cie | "Hello" | Potwierdzenie uwagi |
| **PodwÃ³jne MrugniÄ™cie** | Dwa mrugniÄ™cia w ciÄ…gu 400ms | "Yes" | OdpowiedÅº twierdzÄ…ca |
| **PotrÃ³jne MrugniÄ™cie** | Trzy mrugniÄ™cia w ciÄ…gu 700ms | "No" | OdpowiedÅº negatywna |
| **DÅ‚ugie MrugniÄ™cie** | Trzymanie mrugniÄ™cia >800ms | "Thank you" | WyraÅ¼enie wdziÄ™cznoÅ›ci |
| **MrugniÄ™cie + Spojrzenie** | Dowolne mrugniÄ™cie + kierunek | Niestandardowe frazy | ZÅ‚oÅ¼ona komunikacja |

**Dla poczÄ…tkujÄ…cych:** KaÅ¼dy typ gestu ma specyficzne parametry czasowe. Na przykÅ‚ad, podwÃ³jne mrugniÄ™cie wymaga dwÃ³ch mrugniÄ™Ä‡ w bardzo krÃ³tkim czasie (400 milisekund = 0.4 sekundy). System musi byÄ‡ wystarczajÄ…co inteligentny, aby odrÃ³Å¼niÄ‡ intencjonalne gesty od naturalnych, spontanicznych mrugniÄ™Ä‡.

### ğŸŒ **Zastosowania w Åšwiecie Rzeczywistym**

- **ğŸ¥ Ochrona Zdrowia**: Pacjenci na OIT, komunikacja po operacji, zespÃ³Å‚ locked-in (caÅ‚kowite poraÅ¼enie przy zachowanej Å›wiadomoÅ›ci)
- **â™¿ DostÄ™pnoÅ›Ä‡**: ALS (stwardnienie zanikowe boczne), dystrofia miÄ™Å›niowa, zaburzenia motoryczne
- **â° Tymczasowe**: Rekonwalescencja po utracie mowy, chirurgia jamy ustnej, intubacja
- **ğŸš¨ Sytuacje Awaryjne**: Gdy tradycyjna komunikacja zawodzi

### ğŸ”¬ **Technologia Detekcji**

**System GÅ‚Ã³wny**: MediaPipe FaceLandmarker dla wysokoprecyzyjnego Å›ledzenia punktÃ³w charakterystycznych twarzy  
**System Zapasowy**: WebGazer.js dla szerszej kompatybilnoÅ›ci z przeglÄ…darkami

**WyjaÅ›nienie:** Aplikacja wykorzystuje dwupoziomowÄ… strategiÄ™ detekcji. Najpierw prÃ³buje uÅ¼yÄ‡ MediaPipe, ktÃ³re oferuje najlepszÄ… dokÅ‚adnoÅ›Ä‡ dziÄ™ki zaawansowanym algorytmom uczenia maszynowego. JeÅ›li MediaPipe nie jest dostÄ™pne lub zawodzi, system automatycznie przeÅ‚Ä…cza siÄ™ na WebGazer.js, zapewniajÄ…c dziaÅ‚anie aplikacji nawet na starszych urzÄ…dzeniach.

#### **Detekcja MrugniÄ™Ä‡ (Metoda EAR)**

**WyjaÅ›nienie techniczne:** Eye Aspect Ratio (EAR) to matematyczny sposÃ³b okreÅ›lenia, czy oko jest otwarte czy zamkniÄ™te. Algorytm ten analizuje poÅ‚oÅ¼enie szeÅ›ciu kluczowych punktÃ³w wokÃ³Å‚ oka i oblicza stosunek pionowych do poziomych odlegÅ‚oÅ›ci miÄ™dzy nimi.

- **Algorytm**: Obliczanie Eye Aspect Ratio (EAR) z wykorzystaniem punktÃ³w charakterystycznych twarzy
- **PrÃ³g**: Dynamiczne dostosowywanie progu (typowo ~0.25)
  - **Dla poczÄ…tkujÄ…cych:** Gdy wartoÅ›Ä‡ EAR spada poniÅ¼ej progu 0.25, system rozpoznaje to jako mrugniÄ™cie. PrÃ³g jest "dynamiczny", co oznacza, Å¼e dostosowuje siÄ™ do indywidualnych cech uÅ¼ytkownika podczas kalibracji
- **Wzorce**: Pojedyncze, podwÃ³jne (400ms), potrÃ³jne (700ms), dÅ‚ugie (800ms+) mrugniÄ™cia
- **DokÅ‚adnoÅ›Ä‡**: >95% skutecznoÅ›ci detekcji w optymalnych warunkach

**Matematyka za EAR:**
```
EAR = (||p2-p6|| + ||p3-p5||) / (2 * ||p1-p4||)
```
Gdzie p1-p6 to wspÃ³Å‚rzÄ™dne punktÃ³w wokÃ³Å‚ oka. Gdy oko jest otwarte, EAR jest wysoki (~0.3-0.4). Gdy oko jest zamkniÄ™te, EAR drastycznie spada (<0.2).

#### **Åšledzenie Spojrzenia (Gaze Tracking)**

- **Kalibracja**: System kalibracji 5-punktowej dla spersonalizowanego Å›ledzenia
  - **WyjaÅ›nienie:** UÅ¼ytkownik patrzy kolejno na 5 punktÃ³w na ekranie (zazwyczaj: Å›rodek, gÃ³ra, dÃ³Å‚, lewo, prawo). System "uczy siÄ™" charakterystycznych wzorcÃ³w ruchu Åºrenic dla kaÅ¼dego kierunku spojrzenia u danego uÅ¼ytkownika
- **Kierunki**: Detekcja spojrzenia w lewo, prawo, gÃ³ra, dÃ³Å‚, Å›rodek
- **Precyzja**: PrÃ³g Â±100px (konfigurowalny)
  - **Dla poczÄ…tkujÄ…cych:** System toleruje odchylenie do 100 pikseli od idealnego punktu. DziÄ™ki temu nie trzeba patrzeÄ‡ idealnie dokÅ‚adnie â€“ system jest "wyrozumiaÅ‚y" dla naturalnych ruchÃ³w oka
- **TrwaÅ‚oÅ›Ä‡**: Dane kalibracji przechowywane lokalnie
  - **WyjaÅ›nienie:** Po pierwszej kalibracji dane sÄ… zapisywane w przeglÄ…darce (IndexedDB), wiÄ™c nie musisz kalibrowaÄ‡ systemu przy kaÅ¼dym uÅ¼yciu

### ğŸ—‚ï¸ **Mapowanie Gest-na-MowÄ™**

**Mapowania DomyÅ›lne**: Predefiniowane podstawowe frazy do natychmiastowego uÅ¼ycia  
**Mapowania Niestandardowe**: W peÅ‚ni konfigurowalne przez uÅ¼ytkownika poprzez intuicyjny interfejs  
**Przechowywanie**: Lokalna pamiÄ™Ä‡ przeglÄ…darki z opcjonalnÄ… synchronizacjÄ… w chmurze przez Supabase

**WyjaÅ›nienie:** System dziaÅ‚a jak "sÅ‚ownik gestÃ³w". KaÅ¼dy gest (np. "podwÃ³jne mrugniÄ™cie + spojrzenie w lewo") jest kluczem, a przypisana fraza (np. "PotrzebujÄ™ pomocy") jest wartoÅ›ciÄ…. UÅ¼ytkownik moÅ¼e dowolnie edytowaÄ‡ te powiÄ…zania.

#### **Struktura Mapowania**
```json
{
  "singleBlink": "Hello",
  "doubleBlink": "Yes", 
  "tripleBlink": "No",
  "longBlink": "Thank you",
  "singleBlink_lookLeft": "I need help",
  "doubleBlink_lookUp": "Water please",
  "tripleBlink_lookRight": "Emergency",
  "longBlink_lookDown": "I'm tired"
}
```

**Dla poczÄ…tkujÄ…cych:** PowyÅ¼szy JSON (JavaScript Object Notation) to standardowy format danych. KaÅ¼da linia definiuje jedno mapowanie: nazwa gestu po lewej stronie (klucz), fraza po prawej stronie (wartoÅ›Ä‡). System odczytuje ten plik i wie, co powiedzieÄ‡ dla kaÅ¼dego wykrytego gestu.

#### **Funkcje Personalizacji**
- **ğŸ¨ Edytor Wizualny**: Interfejs mapowania gestÃ³w typu "wskaÅ¼ i kliknij"
- **ğŸ“± Import/Export**: UdostÄ™pnianie mapowaÅ„ miÄ™dzy urzÄ…dzeniami
- **ğŸŒ WielojÄ™zycznoÅ›Ä‡**: Wsparcie dla dowolnego jÄ™zyka i frazy
- **ğŸ”„ Aktualizacje w Czasie Rzeczywistym**: Zmiany stosowane natychmiast bez restartu

-----

## ğŸ”„ **ÅšcieÅ¼ka UÅ¼ytkownika i Funkcje**

### **1. ğŸš€ WdroÅ¼enie (UÅ¼ytkownicy Po Raz Pierwszy)**
- **Powitanie**: Wprowadzenie do moÅ¼liwoÅ›ci Blink Speech
- **Uprawnienia**: Bezpieczne Å¼Ä…danie dostÄ™pu do kamery z jasnymi wyjaÅ›nieniami
  - **WyjaÅ›nienie:** Aplikacja wymaga dostÄ™pu do kamery, aby analizowaÄ‡ ruchy oczu. Przetwarzanie odbywa siÄ™ caÅ‚kowicie lokalnie w przeglÄ…darce â€“ Å¼adne nagranie wideo nie jest wysyÅ‚ane do internetu
- **Kalibracja**: Interaktywna kalibracja spojrzenia w 5 punktach z wizualnÄ… informacjÄ… zwrotnÄ…
  - **Dla poczÄ…tkujÄ…cych:** To kluczowy krok! System "uczy siÄ™" Twoich indywidualnych cech oczu i ruchÃ³w Åºrenic. Patrz uwaÅ¼nie na kaÅ¼dy punkt przez kilka sekund
- **Samouczek**: Opcjonalne Ä‡wiczenie gestÃ³w z informacjÄ… zwrotnÄ… w czasie rzeczywistym

### **2. ğŸ¯ Aktywna Sesja**
- **Detekcja na Å»ywo**: Rozpoznawanie gestÃ³w w czasie rzeczywistym z wizualnymi wskaÅºnikami
  - **WyjaÅ›nienie:** Na ekranie widzisz maÅ‚e ikony lub wskaÅºniki pokazujÄ…ce, kiedy system wykrywa mrugniÄ™cie lub kierunek spojrzenia. To pomaga w nauce i pewnoÅ›ci uÅ¼ywania systemu
- **PodglÄ…d Frazy**: WyraÅºne wyÅ›wietlanie wykrytych fraz przed wypowiedzeniem
- **Niestandardowe Kontrolki**: PrzeÅ‚Ä…cznik mowy, gÅ‚oÅ›noÅ›Ä‡, prÄ™dkoÅ›Ä‡ i wybÃ³r gÅ‚osu
- **Edytor MapowaÅ„**: Edycja mapowaÅ„ gest-na-frazÄ™ na Å¼ywo podczas uÅ¼ytkowania

### **3. ğŸ”§ Funkcje Zaawansowane**
- **Optymalizacja WydajnoÅ›ci**: Adaptacyjna czÄ™stotliwoÅ›Ä‡ klatek i dostosowanie progu
  - **WyjaÅ›nienie:** System automatycznie dostosowuje siÄ™ do mocy Twojego komputera. Na wolniejszym urzÄ…dzeniu zmniejsza czÄ™stotliwoÅ›Ä‡ analizy klatek wideo, aby dziaÅ‚aÄ‡ pÅ‚ynnie
- **DostÄ™pnoÅ›Ä‡**: Wysoki kontrast, duÅ¼y tekst, kompatybilnoÅ›Ä‡ z czytnikami ekranu  
- **Tryb Awaryjny**: Szybki dostÄ™p do krytycznych fraz komunikacyjnych
  - **Dla poczÄ…tkujÄ…cych:** Specjalny tryb umoÅ¼liwiajÄ…cy natychmiastowy dostÄ™p do najwaÅ¼niejszych komunikatÃ³w (np. "Pomocy!", "Å¹le siÄ™ czujÄ™", "Wezwij lekarza")
- **ZarzÄ…dzanie Danymi**: Export/import ustawieÅ„, opcje synchronizacji w chmurze

### **4. ğŸ›¡ï¸ PrywatnoÅ›Ä‡ i BezpieczeÅ„stwo**
- **Przetwarzanie Lokalne**: CaÅ‚a analiza wideo odbywa siÄ™ na urzÄ…dzeniu
  - **WyjaÅ›nienie:** To kluczowa cecha! Obraz z kamery jest analizowany przez JavaScript dziaÅ‚ajÄ…cy w Twojej przeglÄ…darce. Å»adne dane wideo nie sÄ… wysyÅ‚ane na serwery zewnÄ™trzne
- **Brak Transmisji Danych**: Wideo nigdy nie opuszcza Twojej przeglÄ…darki
- **Bezpieczne Przechowywanie**: Zaszyfrowana pamiÄ™Ä‡ lokalna dla wraÅ¼liwych ustawieÅ„
- **Anonimowe UÅ¼ytkowanie**: Nie sÄ… wymagane ani zbierane Å¼adne dane osobowe

-----

---

## âš¡ **WydajnoÅ›Ä‡ i Specyfikacje**

### **Wymagania Systemowe**
- **PrzeglÄ…darka**: Chrome 80+, Firefox 75+, Safari 13+, Edge 80+
- **SprzÄ™t**: 2GB RAM, kamera internetowa (zalecane 720p)
  - **Dla poczÄ…tkujÄ…cych:** Wystarczy standardowy laptop z wbudowanÄ… kamerÄ…. Lepsza jakoÅ›Ä‡ kamery (720p lub wyÅ¼sza) oznacza lepszÄ… dokÅ‚adnoÅ›Ä‡ detekcji
- **SieÄ‡**: Wymagane HTTPS (automatyczne w Å›rodowisku deweloperskim)
  - **WyjaÅ›nienie:** Nowoczesne przeglÄ…darki wymagajÄ… bezpiecznego poÅ‚Ä…czenia HTTPS do dostÄ™pu do kamery ze wzglÄ™dÃ³w bezpieczeÅ„stwa
- **PamiÄ™Ä‡**: ~50MB na peÅ‚nÄ… pamiÄ™Ä‡ podrÄ™cznÄ… aplikacji

### **Metryki WydajnoÅ›ci**
- **OpÃ³Åºnienie Detekcji**: <150ms od gestu do rozpoznania
  - **WyjaÅ›nienie:** System wykrywa mrugniÄ™cie w mniej niÅ¼ jednÄ… szÃ³stÄ… sekundy â€“ tak szybko, Å¼e dla uÅ¼ytkownika wydaje siÄ™ to natychmiastowe
- **OpÃ³Åºnienie Mowy**: <1s od gestu do wyjÅ›cia audio
- **CzÄ™stotliwoÅ›Ä‡ Klatek**: 15-30 FPS (adaptacyjna w zaleÅ¼noÅ›ci od urzÄ…dzenia)
  - **Dla poczÄ…tkujÄ…cych:** FPS (frames per second) to liczba analizowanych klatek wideo na sekundÄ™. System automatycznie dostosowuje tÄ™ wartoÅ›Ä‡ â€“ na mocniejszym komputerze analizuje 30 klatek/s, na sÅ‚abszym 15 klatek/s
- **DokÅ‚adnoÅ›Ä‡**: >95% rozpoznawania gestÃ³w w optymalnych warunkach

### **KompatybilnoÅ›Ä‡ PrzeglÄ…darek**
| Funkcja | Chrome | Firefox | Safari | Edge |
|---------|:------:|:-------:|:------:|:----:|
| MediaPipe | âœ… | âœ… | âœ… | âœ… |
| WebGazer | âœ… | âœ… | âš ï¸ | âœ… |
| Speech API | âœ… | âœ… | âœ… | âœ… |
| IndexedDB | âœ… | âœ… | âœ… | âœ… |

**Legenda:** âœ… = PeÅ‚ne wsparcie, âš ï¸ = CzÄ™Å›ciowe wsparcie lub ograniczenia

---

## ğŸ”§ **Implementacja Techniczna**

### **Aktualna Architektura**

**WyjaÅ›nienie architektury:** System Blink Speech skÅ‚ada siÄ™ z dwÃ³ch gÅ‚Ã³wnych czÄ™Å›ci: frontendu (dziaÅ‚a w przeglÄ…darce uÅ¼ytkownika) i backendu (serwer API). Frontend zajmuje siÄ™ caÅ‚Ä… analizÄ… wideo i wykrywaniem gestÃ³w lokalnie, podczas gdy backend zarzÄ…dza przechowywaniem niestandardowych mapowaÅ„ gestÃ³w i opcjonalnymi funkcjami jak SMS.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           KLIENT (PrzeglÄ…darka)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  React 18 + TypeScript + Vite          â”‚
â”‚  â”œâ”€ MediaPipe (Punkty Charakterystyczne)â”‚
â”‚  â”œâ”€ WebGazer.js (Åšledzenie Wzroku)     â”‚
â”‚  â”œâ”€ Web Speech API (TTS)               â”‚
â”‚  â”œâ”€ LocalForage (Przechowywanie Danych)â”‚
â”‚  â””â”€ Radix UI + Tailwind (Interfejs)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚ HTTPS/WSS
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           SERWER (API)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Next.js API Routes                    â”‚
â”‚  â”œâ”€ Supabase (Baza Danych)             â”‚
â”‚  â”œâ”€ Twilio (Integracja SMS)            â”‚
â”‚  â””â”€ Uwierzytelnianie i Przechowywanie  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Dla poczÄ…tkujÄ…cych - komponenty stosu:**
- **React 18**: Biblioteka JavaScript do budowania interfejsÃ³w uÅ¼ytkownika
- **TypeScript**: JavaScript z typowaniem, ktÃ³re pomaga wykrywaÄ‡ bÅ‚Ä™dy podczas programowania
- **Vite**: Szybkie narzÄ™dzie do budowania aplikacji webowych
- **MediaPipe**: Biblioteka Google do analizy twarzy i punktÃ³w charakterystycznych
- **WebGazer.js**: Biblioteka do Å›ledzenia wzroku w przeglÄ…darce
- **Web Speech API**: Natywne API przeglÄ…darki do syntezy mowy (text-to-speech)
- **LocalForage**: Biblioteka do przechowywania danych lokalnie w przeglÄ…darce
- **Supabase**: Backend-as-a-Service z bazÄ… danych PostgreSQL
- **Twilio**: UsÅ‚uga do wysyÅ‚ania SMS-Ã³w

### **Struktura Projektu**
```
Blink-Speech/
â”œâ”€â”€ frontend/          # Aplikacja React + Vite
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/  # Komponenty UI
â”‚   â”‚   â”œâ”€â”€ hooks/      # Niestandardowe hooki React
â”‚   â”‚   â”œâ”€â”€ pages/      # Komponenty tras  
â”‚   â”‚   â”œâ”€â”€ utils/      # Funkcje narzÄ™dziowe
â”‚   â”‚   â””â”€â”€ types/      # Definicje TypeScript
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ backend/           # Trasy API Next.js
â”‚   â”œâ”€â”€ pages/api/     # Endpointy API
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ docs/             # Kompletna dokumentacja
â””â”€â”€ README.md         # PrzeglÄ…d projektu
```

### Logika Rozpoznawania GestÃ³w

**WyjaÅ›nienie przepÅ‚ywu:** Ta logika znajduje siÄ™ w niestandardowym hooku (np. `hooks/useGestureSpeech.ts`), ktÃ³ry przetwarza strumieÅ„ wideo klatka po klatce. Dla kaÅ¼dej klatki system:
1. Wykrywa twarz i punkty charakterystyczne
2. Oblicza EAR (Eye Aspect Ratio) aby okreÅ›liÄ‡ stan oka
3. OkreÅ›la kierunek spojrzenia na podstawie pozycji Åºrenicy
4. Rejestruje timestampy (znaczniki czasu) mrugniÄ™Ä‡
5. Analizuje wzorce mrugniÄ™Ä‡ aby rozpoznaÄ‡ gesty
6. WywoÅ‚uje odpowiedniÄ… frazÄ™ przez Web Speech API

```ts
// Uproszczona logika przetwarzania klatek
let blinkTimestamps: number[] = [];

async function processFrame(videoElement) {
  // Preferuj MediaPipe dla punktÃ³w charakterystycznych wysokiej wiernoÅ›ci
  const faces = await mediaPipeModel.estimateFaces({ input: videoElement });
  
  if (faces.length > 0) {
    const landmarks = faces[0].scaledMesh;
    const ear = calculateEAR(landmarks); // Oblicz Eye Aspect Ratio
    const gazeDir = gazeDirection(landmarks);

    // Wykryj mrugniÄ™cie gdy EAR spada poniÅ¼ej progu
    if (ear < DYNAMIC_BLINK_THRESHOLD) {
      blinkTimestamps.push(performance.now());
    }
    // Wykryj wzorzec z timestampÃ³w i kierunku spojrzenia, nastÄ™pnie mÃ³w
    detectPatternAndSpeak(blinkTimestamps, gazeDir); 
  } else {
    // PowrÃ³t do WebGazer jeÅ›li MediaPipe zawiedzie
    // WebGazer moÅ¼e uÅ¼yÄ‡ jasnoÅ›ci obszarÃ³w oka jako przybliÅ¼enia
  }
}
```

**WyjaÅ›nienie funkcji calculateEAR:**
Funkcja `calculateEAR` implementuje wzÃ³r matematyczny opisany wczeÅ›niej. Pobiera 6 punktÃ³w charakterystycznych wokÃ³Å‚ oka i oblicza stosunek odlegÅ‚oÅ›ci pionowych do poziomych. Niska wartoÅ›Ä‡ (< 0.25) oznacza zamkniÄ™te oko.

**WyjaÅ›nienie funkcji detectPatternAndSpeak:**
Ta funkcja analizuje tablicÄ™ `blinkTimestamps` (znacznikÃ³w czasu mrugniÄ™Ä‡) aby okreÅ›liÄ‡, czy wykryto specyficzny wzorzec:
- JeÅ›li dwa timestampy sÄ… w odlegÅ‚oÅ›ci < 400ms = podwÃ³jne mrugniÄ™cie
- JeÅ›li trzy timestampy sÄ… w odlegÅ‚oÅ›ci < 700ms = potrÃ³jne mrugniÄ™cie
- JeÅ›li jedno mrugniÄ™cie trwa > 800ms = dÅ‚ugie mrugniÄ™cie
System nastÄ™pnie Å‚Ä…czy wykryty wzorzec z kierunkiem spojrzenia i wyszukuje odpowiedniÄ… frazÄ™ w mapowaniu.

### Endpointy API i TrwaÅ‚oÅ›Ä‡ Danych

Niestandardowe mapowania fraz sÄ… przechowywane w bazie danych **Supabase** i dostÄ™pne poprzez trasÄ™ API Next.js.

**WyjaÅ›nienie architektury danych:** 
- **Frontend** (przeglÄ…darka): Tymczasowo przechowuje mapowania w LocalStorage/IndexedDB
- **Backend** (Supabase): Trwale przechowuje mapowania w bazie PostgreSQL
- **API** (Next.js): PoÅ›redniczy miÄ™dzy frontendem a bazÄ… danych

**Schemat Bazy Danych:**

  * **Tabela**: `patterns`
  * **Kolumny**:
      * `sid`: `TEXT PRIMARY KEY` - unikalny identyfikator sesji uÅ¼ytkownika
      * `mapping`: `JSONB` - obiekt JSON zawierajÄ…cy peÅ‚ne mapowanie gestÃ³w

**WyjaÅ›nienie typÃ³w danych:**
- `TEXT PRIMARY KEY`: Kolumna tekstowa bÄ™dÄ…ca gÅ‚Ã³wnym kluczem (unikalny identyfikator rekordu)
- `JSONB`: Specjalny typ PostgreSQL do przechowywania danych JSON w binarnym formacie â€“ szybszy i bardziej wydajny niÅ¼ zwykÅ‚y tekst JSON

**Trasa API**: `pages/api/patterns/[sid].ts`

```ts
// pages/api/patterns/[sid].ts
import { createClient } from '@supabase/supabase-js';

// Inicjalizacja klienta Supabase
const sb = createClient(process.env.NEXT_PUBLIC_SUPABASE_URL, process.env.SUPABASE_SERVICE_ROLE_KEY);

export default async function handler(req, res) {
  const { sid } = req.query;

  if (req.method === 'GET') {
    // Pobierz mapowanie dla danego uÅ¼ytkownika
    const { data } = await sb.from('patterns').select('mapping').eq('sid', sid).single();
    // ZwrÃ³Ä‡ niestandardowe mapowanie lub domyÅ›lne
    res.status(200).json({ mapping: data?.mapping ?? defaultMapping });
  } 
  else if (req.method === 'POST') {
    const { mapping } = req.body;
    // 'upsert' tworzy lub aktualizuje mapowanie uÅ¼ytkownika
    // JeÅ›li rekord z danym sid istnieje - aktualizuje, jeÅ›li nie - tworzy nowy
    await sb.from('patterns').upsert({ sid, mapping }, { onConflict: 'sid' });
    res.status(201).json({ success: true });
  }
}
```

**Dla poczÄ…tkujÄ…cych - metody HTTP:**
- **GET**: Pobiera dane (tutaj: odczytuje mapowanie z bazy)
- **POST**: WysyÅ‚a dane do zapisania (tutaj: zapisuje/aktualizuje mapowanie)
- **upsert**: Operacja "update or insert" - jeÅ›li rekord istnieje to go aktualizuje, jeÅ›li nie to tworzy nowy

### Synteza Mowy (Text-to-Speech)

Prosta funkcja narzÄ™dziowa opakowuje Web Speech API dla Å‚atwego uÅ¼ycia.

```ts
// lib/tts.ts
export function speak(text: string, lang = 'en-US') {
  if (!text || typeof window === 'undefined') return;
  const utterance = new SpeechSynthesisUtterance(text);
  utterance.lang = lang;
  window.speechSynthesis.speak(utterance);
}
```

**WyjaÅ›nienie dziaÅ‚ania:**
1. Funkcja sprawdza czy tekst nie jest pusty i czy kod dziaÅ‚a w przeglÄ…darce (nie na serwerze)
2. Tworzy obiekt `SpeechSynthesisUtterance` - reprezentuje tekst do wypowiedzenia
3. Ustawia jÄ™zyk (domyÅ›lnie angielski amerykaÅ„ski)
4. WywoÅ‚uje `window.speechSynthesis.speak()` - natywne API przeglÄ…darki syntetyzuje i wypowiada tekst

**Dla poczÄ…tkujÄ…cych:** Web Speech API jest wbudowane w nowoczesne przeglÄ…darki. Nie wymaga Å¼adnych zewnÄ™trznych bibliotek czy poÅ‚Ä…czenia internetowego - synteza gÅ‚osu dzieje siÄ™ caÅ‚kowicie lokalnie w przeglÄ…darce.


---

## ğŸš€ **RozpoczÄ™cie Pracy - Kolejne Kroki**

### **Dla UÅ¼ytkownikÃ³w**
1. ğŸ“– Przeczytaj [Przewodnik UÅ¼ytkownika](./docs/user-guide.md) aby uzyskaÄ‡ szczegÃ³Å‚owe instrukcje uÅ¼ytkowania
2. ğŸ”§ SprawdÅº [RozwiÄ…zywanie ProblemÃ³w](./docs/troubleshooting.md) jeÅ›li napotkasz problemy
3. âš™ï¸ Dowiedz siÄ™ o opcjach [Konfiguracji](./docs/configuration.md)

### **Dla ProgramistÃ³w**
1. ğŸ› ï¸ PostÄ™puj zgodnie z [Przewodnikiem Instalacji](./docs/installation.md) aby skonfigurowaÄ‡ Å›rodowisko
2. ğŸ’» Przeczytaj [Przewodnik Deweloperski](./docs/development-guide.md) aby poznaÄ‡ przepÅ‚ywy pracy  
3. ğŸ—ï¸ Zrozum projekt [Architektury](./docs/architecture.md)
4. ğŸ§© Eksploruj [DokumentacjÄ™ KomponentÃ³w](./docs/frontend-components.md)

### **Dla WdroÅ¼enia**
1. ğŸš€ PostÄ™puj zgodnie z [Przewodnikiem WdroÅ¼enia](./docs/deployment.md) dla Å›rodowiska produkcyjnego
2. ğŸ”’ Przejrzyj kwestie bezpieczeÅ„stwa i najlepsze praktyki
3. ğŸ“Š Skonfiguruj monitorowanie i analitykÄ™

---

## ğŸ“š **Dodatkowe Zasoby**

**WyjaÅ›nienie:** PoniÅ¼sza tabela zawiera linki do zewnÄ™trznych bibliotek, frameworkÃ³w i zasobÃ³w edukacyjnych wykorzystywanych w projekcie Blink Speech. KaÅ¼dy zasÃ³b jest opisany z perspektywy jego roli w projekcie.

| Kategoria | Nazwa i Link | Cel |
|----------|-------------|---------|
| **Åšledzenie Wzroku** | [WebGazer.js](https://webgazer.cs.brown.edu/) | Åšledzenie spojrzenia w przeglÄ…darce z uÅ¼yciem kamery internetowej, dziaÅ‚a bez dodatkowego sprzÄ™tu. **Dla poczÄ…tkujÄ…cych:** To biblioteka JavaScript, ktÃ³ra uÅ¼ywa uczenia maszynowego do przewidywania, gdzie uÅ¼ytkownik patrzy na ekran, bazujÄ…c tylko na obrazie z kamery. |
| **Åšledzenie Wzroku** | [MediaPipe FaceLandmarker (Web)](https://ai.google.dev/edge/mediapipe/solutions/vision/face_landmarker/web_js) | Wysokiej jakoÅ›ci detekcja punktÃ³w charakterystycznych twarzy i tÄ™czÃ³wki w przeglÄ…darce przez TensorFlow.js. **WyjaÅ›nienie:** MediaPipe to zestaw narzÄ™dzi Google do analizy mediÃ³w. FaceLandmarker wykrywa 468 punktÃ³w 3D na twarzy w czasie rzeczywistym. |
| **Detekcja MrugniÄ™Ä‡** | [Eye Aspect Ratio (EAR) Method](https://www.pyimagesearch.com/2017/04/24/eye-blink-detection-opencv-python-dlib/) | Technika detekcji mrugniÄ™Ä‡ wykorzystujÄ…ca punkty charakterystyczne twarzy i wspÃ³Å‚czynnik proporcji. **WyjaÅ›nienie techniczna:** Metoda EAR zostaÅ‚a opublikowana w 2016 roku i staÅ‚a siÄ™ standardem w detekcji mrugniÄ™Ä‡ ze wzglÄ™du na prostotÄ™ i skutecznoÅ›Ä‡. |
| **PrzykÅ‚adowy Kod Detekcji MrugniÄ™Ä‡** | [LearnOpenCV Eye Blink Detection](https://github.com/spmallick/learnopencv/tree/master/Eye-Blink-Detection) | Implementacja detekcji mrugniÄ™Ä‡ EAR w OpenCV + Dlib. **Dla poczÄ…tkujÄ…cych:** To repozytorium GitHub zawiera dziaÅ‚ajÄ…cy przykÅ‚ad kodu w Pythonie, ktÃ³ry moÅ¼esz uruchomiÄ‡ lokalnie aby zrozumieÄ‡ koncepcjÄ™. |
| **WyjÅ›cie Mowy** | [Web Speech API (MDN)](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API) | Natywne API przeglÄ…darki do syntezy mowy (Text-to-Speech) i rozpoznawania mowy. **WyjaÅ›nienie:** To standardowe API dostÄ™pne we wszystkich nowoczesnych przeglÄ…darkach â€“ nie wymaga instalacji dodatkowych bibliotek. |
| **WyjÅ›cie Mowy (Python)** | [gTTS â€“ Google Text-to-Speech](https://github.com/pndurette/gTTS) | Biblioteka po stronie serwera do syntezy mowy w Pythonie. **Nota:** Nie jest uÅ¼ywana w obecnej wersji Blink Speech (ktÃ³ra dziaÅ‚a caÅ‚kowicie w przeglÄ…darce), ale moÅ¼e byÄ‡ przydatna dla rozszerzeÅ„ serwerowych. |
| **Framework Frontend** | [Next.js](https://nextjs.org/) | Framework React do budowania peÅ‚nowarstwowych aplikacji webowych. **Dla poczÄ…tkujÄ…cych:** Next.js rozszerza React o funkcje serwerowe, routing oparty na plikach i optymalizacje wydajnoÅ›ci. |
| **ZarzÄ…dzanie Stanem** | [Zustand](https://zustand-demo.pmnd.rs/) | Lekka biblioteka do zarzÄ…dzania stanem dla React. **WyjaÅ›nienie:** Zustand pozwala rÃ³Å¼nym komponentom React wspÃ³Å‚dzieliÄ‡ i synchronizowaÄ‡ dane bez "prop drilling" (przekazywania props przez wiele poziomÃ³w). |
| **Stylizacja** | [Tailwind CSS](https://tailwindcss.com/) | Framework CSS typu utility-first do stylizacji. **Dla poczÄ…tkujÄ…cych:** Zamiast pisaÄ‡ wÅ‚asne klasy CSS, uÅ¼ywasz gotowych klas jak `flex`, `text-center`, `bg-blue-500` bezpoÅ›rednio w HTML/JSX. |
| **Przechowywanie TrwaÅ‚e** | [localForage](https://localforage.github.io/localForage/) | Wrapper dla IndexedDB, WebSQL i localStorage do przechowywania danych kalibracji. **WyjaÅ›nienie:** localForage automatycznie wybiera najlepszÄ… dostÄ™pnÄ… metodÄ™ przechowywania w danej przeglÄ…darce, ukrywajÄ…c zÅ‚oÅ¼onoÅ›Ä‡ API. |
| **Backend & Baza Danych** | [Supabase](https://supabase.com/) | Backend-as-a-Service z PostgreSQL, uwierzytelnianiem i funkcjami bezserwerowymi. **Dla poczÄ…tkujÄ…cych:** Supabase to "otwarta alternatywa dla Firebase" â€“ zapewnia gotowÄ… bazÄ™ danych, API i uwierzytelnianie bez koniecznoÅ›ci konfigurowania wÅ‚asnego serwera. |
| **Komunikacja w Czasie Rzeczywistym** | [Supabase Realtime](https://supabase.com/docs/guides/realtime) | Aktualizacje w czasie rzeczywistym oparte na WebSocket z Supabase. **WyjaÅ›nienie:** Pozwala na natychmiastowÄ… synchronizacjÄ™ zmian w bazie danych miÄ™dzy urzÄ…dzeniami bez odÅ›wieÅ¼ania strony. |
| **Opcjonalne API SMS** | [Twilio SMS API](https://www.twilio.com/docs/sms) | Programowe wysyÅ‚anie fraz jako wiadomoÅ›ci SMS. **Przypadek uÅ¼ycia:** UÅ¼ytkownik moÅ¼e skonfigurowaÄ‡ wysyÅ‚anie pilnych komunikatÃ³w (np. "Pomocy!") bezpoÅ›rednio jako SMS do opiekuna. |
| **Biblioteka Widzenia Komputerowego** | [OpenCV.js](https://docs.opencv.org/4.x/d5/d10/tutorial_js_root.html) | Wersja JavaScript OpenCV do analizy obrazu/wideo. **WyjaÅ›nienie:** OpenCV (Open Computer Vision) to najpopularniejsza biblioteka do przetwarzania obrazÃ³w. Wersja .js dziaÅ‚a w przeglÄ…darce. |
| **Modele ML w JS** | [TensorFlow.js](https://www.tensorflow.org/js) | Uruchamianie modeli uczenia maszynowego bezpoÅ›rednio w przeglÄ…darce. **Dla poczÄ…tkujÄ…cych:** TensorFlow.js pozwala na inference (przewidywania) modeli AI bez wysyÅ‚ania danych na serwer â€“ wszystko dzieje siÄ™ lokalnie w przeglÄ…darce uÅ¼ytkownika. |
| **PrzykÅ‚ad Åšledzenia GestÃ³w** | [GazeTracking (Python)](https://github.com/antoinelame/GazeTracking) | Biblioteka do Å›ledzenia ruchÃ³w oczu w Pythonie, przydatna do prototypowania. **Nota:** Napisana w Pythonie, wiÄ™c nie jest bezpoÅ›rednio uÅ¼ywana w projekcie webowym, ale doskonaÅ‚a do nauki koncepcji i eksperymentÃ³w. |

